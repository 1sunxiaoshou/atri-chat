# 中间件管理模块文档

## 概述

中间件管理模块为 Agent 提供了可插拔的中间件机制，用于在消息处理流程中插入额外的逻辑。目前主要支持摘要中间件（SummarizationMiddleware），用于自动压缩长对话历史。

## 核心组件

### 1. SummarizationConfig - 摘要中间件配置

定义摘要中间件的触发条件和行为。

```python
from core.middleware import SummarizationConfig

config = SummarizationConfig(
    enabled=True,
    model="gpt-4o-mini",
    trigger_tokens=4000,      # 当消息超过 4000 tokens 时触发
    trigger_messages=None,    # 或者当消息数超过指定数量时触发
    keep_messages=20          # 保留最近 20 条消息
)
```

**字段说明：**
- `enabled`: 是否启用摘要功能
- `model`: 用于生成摘要的模型（建议使用快速且便宜的模型）
- `trigger_tokens`: 触发摘要的 token 数阈值
- `trigger_messages`: 触发摘要的消息数阈值（与 trigger_tokens 二选一）
- `keep_messages`: 摘要后保留的最近消息数

### 2. MiddlewareConfig - 中间件配置集合

管理角色的所有中间件配置。

```python
from core.middleware import MiddlewareConfig, SummarizationConfig

middleware_config = MiddlewareConfig(
    character_id=1,
    summarization=SummarizationConfig(
        enabled=True,
        model="gpt-4o-mini",
        trigger_tokens=4000,
        keep_messages=20
    )
)
```

### 3. MiddlewareManager - 中间件管理器

负责创建和管理中间件实例。

```python
from core.middleware import MiddlewareManager
from core.storage import AppStorage

# 初始化
storage = AppStorage("data/app.db")
manager = MiddlewareManager(storage)

# 获取角色的中间件列表
middlewares = manager.get_character_middleware(character_id=1)

# 更新摘要配置
manager.update_summarization_config(
    character_id=1,
    enabled=True,
    model="gpt-4o-mini",
    trigger_tokens=5000,
    keep_messages=15
)
```

## 摘要中间件工作原理

摘要中间件会监控对话历史的长度，当满足触发条件时：

1. **触发检测**：检查消息 token 数或消息数量是否超过阈值
2. **生成摘要**：使用指定模型对历史消息生成简洁摘要
3. **压缩历史**：用摘要替换旧消息，保留最近的 N 条消息
4. **继续对话**：使用压缩后的历史继续对话

```
原始历史（100 条消息，8000 tokens）
    ↓ 触发摘要（trigger_tokens=4000）
摘要 + 最近 20 条消息（约 2000 tokens）
    ↓ 继续对话
节省 token 使用，降低成本
```

## 使用示例

### 示例 1：为角色配置摘要中间件

```python
from core.storage import AppStorage
from core.middleware import MiddlewareManager

# 初始化
storage = AppStorage("data/app.db")
manager = MiddlewareManager(storage)

# 配置摘要中间件
manager.update_summarization_config(
    character_id=1,
    enabled=True,
    model="gpt-4o-mini",
    trigger_tokens=4000,
    keep_messages=20
)

# 获取中间件实例
middlewares = manager.get_character_middleware(character_id=1)
print(f"已配置 {len(middlewares)} 个中间件")
```

### 示例 2：在 Agent 中使用中间件

```python
from core.agent_manager import AgentManager

# 创建 Agent 管理器
agent_manager = AgentManager(
    db_path="data/app.db",
    store_path="data/store.db"
)

# 创建角色（自动加载中间件配置）
character_id = agent_manager.create_character(
    name="助手",
    system_prompt="你是一个有帮助的 AI 助手",
    model_provider="openai",
    model_id="gpt-4o-mini"
)

# 配置摘要中间件
agent_manager.middleware_manager.update_summarization_config(
    character_id=character_id,
    enabled=True,
    trigger_tokens=3000,
    keep_messages=15
)

# 创建 Agent（中间件会自动应用）
agent = agent_manager.create_agent(character_id)

# 长对话会自动触发摘要
for i in range(50):
    response = agent.invoke({
        "messages": [("user", f"这是第 {i+1} 条消息")]
    })
```

### 示例 3：动态调整摘要配置

```python
# 根据对话场景调整配置

# 场景 1：长文档分析（需要更多上下文）
manager.update_summarization_config(
    character_id=1,
    trigger_tokens=8000,
    keep_messages=30
)

# 场景 2：快速问答（可以更激进地压缩）
manager.update_summarization_config(
    character_id=1,
    trigger_tokens=2000,
    keep_messages=10
)

# 场景 3：临时禁用摘要
manager.update_summarization_config(
    character_id=1,
    enabled=False
)
```

### 示例 4：自定义摘要模型

```python
# 使用不同的模型进行摘要
manager.update_summarization_config(
    character_id=1,
    model="gpt-3.5-turbo",  # 更便宜的模型
    trigger_tokens=3000,
    keep_messages=20
)

# 或使用本地模型
manager.update_summarization_config(
    character_id=1,
    model="ollama/llama3",  # 本地模型
    trigger_tokens=2000,
    keep_messages=15
)
```

## 配置建议

### 触发条件选择

| 场景 | trigger_tokens | trigger_messages | keep_messages |
|------|----------------|------------------|---------------|
| 短对话 | 2000-3000 | 15-20 | 10-15 |
| 中等对话 | 4000-6000 | 30-40 | 20-25 |
| 长对话 | 8000-10000 | 50-60 | 30-40 |
| 文档分析 | 10000+ | - | 40-50 |

### 模型选择

| 模型 | 速度 | 成本 | 质量 | 适用场景 |
|------|------|------|------|----------|
| gpt-4o-mini | 快 | 低 | 好 | 通用推荐 |
| gpt-3.5-turbo | 很快 | 很低 | 中 | 成本敏感 |
| gpt-4o | 中 | 高 | 很好 | 高质量要求 |
| 本地模型 | 中 | 免费 | 中 | 隐私要求 |

## 最佳实践

1. **合理设置阈值**：根据实际对话长度和模型上下文窗口设置 trigger_tokens
2. **保留足够消息**：keep_messages 应该保留足够的上下文以保持对话连贯性
3. **选择合适模型**：摘要模型不需要太强大，使用快速便宜的模型即可
4. **监控效果**：定期检查摘要质量，必要时调整配置
5. **场景化配置**：不同类型的角色使用不同的摘要策略

## 扩展中间件

未来可以添加更多中间件类型：

```python
# 示例：添加新的中间件类型
class TranslationConfig(BaseModel):
    """翻译中间件配置"""
    enabled: bool = True
    target_language: str = "zh"
    source_language: str = "auto"

class MiddlewareConfig(BaseModel):
    character_id: int
    summarization: Optional[SummarizationConfig] = None
    translation: Optional[TranslationConfig] = None  # 新增
```

## 注意事项

- 摘要会消耗额外的 API 调用和 token
- 摘要质量取决于所选模型的能力
- 过于频繁的摘要可能导致信息丢失
- 建议在开发环境中测试摘要效果后再应用到生产环境

## 相关依赖

```bash
# LangChain 核心（包含中间件支持）
pip install langchain>=0.3.0
```
